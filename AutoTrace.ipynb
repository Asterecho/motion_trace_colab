{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AutoTrace.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "NxA42Uase5hk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# MMD自動トレースキット準備"
      ]
    },
    {
      "metadata": {
        "id": "aCQg_tD0e9v0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "このノートブックでは、MMD自動トレースの準備と実行を行います。\n",
        "\n",
        "\n",
        "画面左上の「＞」をクリックして下さい。目次が開きます。\n",
        "\n",
        "![目次](https://drive.google.com/uc?export=view&id=1x8AdFNmsIQPrtYptBf_NXPRNBJF8ON8z)\n",
        "\n",
        "\n",
        "ノートブックを上から順に確認し、以下手順をひとつずつ実行してください。\n",
        "\n",
        "- **「ランタイムをGPUに変更」**\n",
        "  - ランタイムがGPUに変更できたことを確認します\n",
        "  - 変更のやり方は、導入編をご確認ください\n",
        "- **「Googleドライブとの連携」**\n",
        "  - Googleドライブとの連携ができたことを確認します\n",
        "  - 連携のやり方は、導入編をご確認ください\n",
        "- **「準備開始」**\n",
        "    - 準備セクションのセルをすべて実行します\n",
        "      - この処理で、MMD自動トレースに必要なプログラムやデータがすべてcolab上に作成されます。\n",
        "      - 大体40～60分くらいかかります。\n",
        "- **「MMD自動トレースキット実行」**\n",
        "  - 実行セクションのセルを上から順番に1つずつ実行します\n",
        "    - トレース元動画の指定\n",
        "    - トレースパラメーターの設定\n",
        "    - トレース処理実行\n",
        "    - 人数にもよりますが、6000Fで大体50～60分くらいかかります。\n"
      ]
    },
    {
      "metadata": {
        "id": "F8qp5VzAWyGl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## ランタイムをGPUに変更"
      ]
    },
    {
      "metadata": {
        "id": "UNrlmW0-W1D1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "ヘッダの \"ランタイム\"　＞　\"ランタイムのタイプを変更\"　＞　\"GPU\"　を選択して下さい。\n",
        "\n",
        "変更できたら、下のセルを実行して下さい。"
      ]
    },
    {
      "metadata": {
        "id": "P3zDmyRDwRs0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "! nvcc --version\n",
        "! nvidia-smi"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oo-BfaAdw9cN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**【OK】**\n",
        "\n",
        "下記のように表示されていたら成功です。\n",
        "\n",
        "![GPU変更成功](https://drive.google.com/uc?export=view&id=17CG697kiTLkwVOdH1wg2W3MSB-hyi9u5)\n",
        "\n",
        "---\n",
        "\n",
        "**【NG】**\n",
        "\n",
        "下記のように表示されていたら、ランタイムの変更に失敗しているので、導入編を再度確認して、ランタイムを変更してください。\n",
        "\n",
        "![GPU切り替え失敗](https://drive.google.com/uc?export=view&id=1tufSuT7ocWxv3HkrmA5kwlemhu0gv6Je)"
      ]
    },
    {
      "metadata": {
        "id": "o8OpmLpVp4qr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Googleドライブとの連携"
      ]
    },
    {
      "metadata": {
        "id": "FmdrRx_Tp8Bk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Googleドライブの `autotrace` フォルダと連携します。\n",
        "\n",
        "下のセルを実行してください。"
      ]
    },
    {
      "metadata": {
        "id": "_f1KFUn_qGsU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# Googleドライブマウント\n",
        "drive.mount('/gdrive')\n",
        "\n",
        "# 起点ディレクトリ\n",
        "base_path = \"/gdrive/My Drive/autotrace\"\n",
        "\n",
        "! echo \"autotraceフォルダの中身 -----------\"\n",
        "! ls -l \"$base_path\"\n",
        "! echo \"--------------------\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "38aL3FiVWvmN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 準備開始"
      ]
    },
    {
      "metadata": {
        "id": "6k716wWUxT4F",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "ここでは、準備セクションのセルを一括で実行します。\n",
        "\n",
        "目次の「MMD自動トレースキット実行」を選択して下さい。\n",
        "\n",
        "![実行選択](https://drive.google.com/uc?export=view&id=1YaSrtio06mmu94RUkU5dSolNtFqPiAnV)\n",
        "\n",
        "ヘッダの　\"ランタイム\"　＞　\"より前のセルを実行\"　を選択すると、準備セクションのすべてのセルが順次実行されます。\n",
        "\n",
        "![すべてのセルを実行](https://drive.google.com/uc?export=view&id=1rIbVI_Qyjs8idEzkIR0IBIx6Dbp3te08)\n",
        "\n",
        "---\n",
        "\n",
        "** 【OK】**\n",
        "\n",
        "画面の一番下に、以下のように出力されれば、完了です。\n",
        "\n",
        "![処理成功](https://drive.google.com/uc?export=view&id=1D21xezv6QN0RQF5ZU_LR7PRnOk0Dw4Sc)\n",
        "\n",
        "大体40～60分くらいかかります。\n",
        "\n",
        "---\n",
        "\n",
        "**【NG】**\n",
        "\n",
        "![処理失敗](https://drive.google.com/uc?export=view&id=1t-immeF3Ji1_GBNatZOG1C07j42de4Rq)\n",
        "\n",
        "最後の行に、「No such file or directory」と出力されていたら失敗です。\n",
        "\n",
        "解決方法が分からない場合、ノートブックを共有してください。"
      ]
    },
    {
      "metadata": {
        "id": "E-h6RWCXnZU8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 環境設定"
      ]
    },
    {
      "metadata": {
        "id": "IPiDvSBanScr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 処理時間計測のための開始時間\n",
        "import time\n",
        "start_time = time.time()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9UMIfs3snkRm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Openposeバージョンタグ\n",
        "ver_openpose = \"v1.4.0\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iWQcbt_rnblK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# MMD自動トレースキットバージョンタグ\n",
        "ver_tag = \"ver1.00\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EK-WUxgciv9V",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## cmake"
      ]
    },
    {
      "metadata": {
        "id": "djxuuJjKix5B",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "! wget -c \"https://github.com/Kitware/CMake/releases/download/v3.13.4/cmake-3.13.4.tar.gz\"\n",
        "! tar xf cmake-3.13.4.tar.gz\n",
        "! cd cmake-3.13.4 && ./configure && make && sudo make install"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Viqw8qJqfDyf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Openpose"
      ]
    },
    {
      "metadata": {
        "id": "a-fnE9kwgcfg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# ライブラリのインストール\n",
        "\n",
        "# Basic\n",
        "! sudo apt-get --assume-yes update\n",
        "! sudo apt-get --assume-yes install build-essential\n",
        "# OpenCV\n",
        "! sudo apt-get --assume-yes install libopencv-dev\n",
        "# General dependencies\n",
        "! sudo apt-get --assume-yes install libatlas-base-dev libprotobuf-dev libleveldb-dev libsnappy-dev libhdf5-serial-dev protobuf-compiler\n",
        "! sudo apt-get --assume-yes install --no-install-recommends libboost-all-dev\n",
        "# Remaining dependencies, 14.04\n",
        "! sudo apt-get --assume-yes install libgflags-dev libgoogle-glog-dev liblmdb-dev\n",
        "# Python2 libs\n",
        "! sudo apt-get --assume-yes install python-setuptools python-dev build-essential\n",
        "! sudo easy_install pip\n",
        "! sudo -H pip install --upgrade numpy protobuf opencv-python\n",
        "# Python3 libs\n",
        "! sudo apt-get --assume-yes install python3-setuptools python3-dev build-essential\n",
        "! sudo apt-get --assume-yes install python3-pip\n",
        "! sudo -H pip3 install --upgrade numpy protobuf opencv-python\n",
        "# OpenCV 2.4 -> Added as option\n",
        "# # sudo apt-get --assume-yes install libopencv-dev\n",
        "# OpenCL Generic\n",
        "! sudo apt-get --assume-yes install opencl-headers ocl-icd-opencl-dev\n",
        "! sudo apt-get --assume-yes install libviennacl-dev"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eMCKuBuagoFo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#  Openpose の clone\n",
        "#! git clone  --depth 1 -b \"$ver_openpose\" https://github.com/CMU-Perceptual-Computing-Lab/openpose.git \n",
        "! git clone  --depth 1 https://github.com/CMU-Perceptual-Computing-Lab/openpose.git     "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BSls4lfOgwG0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#  Openpose の モデルデータDL\n",
        "! cd openpose/models && ./getModels.sh"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8ld2HCrvg7c3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Openpose の ビルド\n",
        "! sed -i 's/execute_process(COMMAND git checkout master WORKING_DIRECTORY ${CMAKE_SOURCE_DIR}\\/3rdparty\\/caffe)/execute_process(COMMAND git checkout f019d0dfe86f49d1140961f8c7dec22130c83154 WORKING_DIRECTORY ${CMAKE_SOURCE_DIR}\\/3rdparty\\/caffe)/g' openpose/CMakeLists.txt\n",
        "! cd openpose && rm -r build || true && mkdir build && cd build && cmake .. && make -j`nproc` # example demo usage"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lZLayojmhDdI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## FCRN-DepthPrediction-vmd"
      ]
    },
    {
      "metadata": {
        "id": "rJw3lnjKhIp7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# FCRN-DepthPrediction-vmd の clone\n",
        "# FIXME ブランチ指定\n",
        "! git clone  --depth 1 -b \"20190220\" https://github.com/miu200521358/FCRN-DepthPrediction-vmd.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sNbLo-sBhlcL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# FCRN-DepthPrediction-vmd の モデルデータDL\n",
        "\n",
        "# モデルデータ の導入\n",
        "! mkdir -p ./FCRN-DepthPrediction-vmd/tensorflow/data\n",
        "\n",
        "# モデルデータのダウンロード\n",
        "! cd  ./FCRN-DepthPrediction-vmd/tensorflow/data && wget -c \"http://campar.in.tum.de/files/rupprecht/depthpred/NYU_FCRN-checkpoint.zip\" && unzip NYU_FCRN-checkpoint.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Gvkd3YfCiVJ8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 3d-pose-baseline-vmd"
      ]
    },
    {
      "metadata": {
        "id": "w3Uh4e6liYPg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 3d-pose-baseline-vmd の clone\n",
        "! git clone  --depth 1 -b \"$ver_tag\" https://github.com/miu200521358/3d-pose-baseline-vmd.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Iw7kI9zhi_7k",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 3d-pose-baseline-vmd の Human3.6MモデルデータDL\n",
        "\n",
        "# Human3.6Mモデルデータ の導入\n",
        "! mkdir -p ./3d-pose-baseline-vmd/data\n",
        "\n",
        "# Human3.6Mモデルデータのダウンロード\n",
        "! cd  ./3d-pose-baseline-vmd/data && wget -c \"https://www.dropbox.com/s/e35qv3n6zlkouki/h36m.zip\" && unzip h36m.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dclND00zjGdN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 3d-pose-baseline-vmd の 学習データDL\n",
        "\n",
        "# 3d-pose-baseline用学習データ の導入\n",
        "! mkdir -p ./3d-pose-baseline-vmd/experiments\n",
        "\n",
        "# 3d-pose-baseline用学習データのダウンロード\n",
        "file_id = \"1v7ccpms3ZR8ExWWwVfcSpjMsGscDYH7_\"\n",
        "file_name = \"experiments.zip\"\n",
        "! cd  ./3d-pose-baseline-vmd && curl -sc ./cookie \"https://drive.google.com/uc?export=download&id=$file_id\" > /dev/null\n",
        "code = \"$(awk '/_warning_/ {print $NF}' ./cookie)\"  \n",
        "! cd  ./3d-pose-baseline-vmd && curl -Lb ./cookie \"https://drive.google.com/uc?export=download&confirm=$code&id=$file_id\" -o \"$file_name\"\n",
        "! cd  ./3d-pose-baseline-vmd && unzip experiments.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jruMP1J4jLXX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## VMD-3d-pose-baseline-multi"
      ]
    },
    {
      "metadata": {
        "id": "87ZPjj6IjPgj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# VMD-3d-pose-baseline-multi の clone\n",
        "\n",
        "! git clone  --depth 1 -b \"$ver_tag\" https://github.com/miu200521358/VMD-3d-pose-baseline-multi.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fnuSwMT9jW5E",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# VMD-3d-pose-baseline-multi のライブラリ\n",
        "\n",
        "! sudo apt-get install python3-pyqt5  \n",
        "! sudo apt-get install pyqt5-dev-tools\n",
        "! sudo apt-get install qttools5-dev-tools"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GIp8lIjZY7ih",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 準備結果確認"
      ]
    },
    {
      "metadata": {
        "id": "T8vXn_ZE6bHk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# サンプルの実行確認\n",
        "! cd openpose && ./build/examples/openpose/openpose.bin --video examples/media/video.avi --write_json ./output/ --display 0  --write_video ./output/openpose.avi"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gZjjbPz0llYs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "elapsed_time = (time.time() - start_time) / 60\n",
        "\n",
        "! echo \"■■■■■■■■■■■■■■■■■■■■■■■■\"\n",
        "! echo \"■■すべての処理が終了しました\"\n",
        "! echo \"■■\"\n",
        "! echo \"■■処理にかかった時間：\" \"$elapsed_time\" \"分\"\n",
        "! echo \"■■■■■■■■■■■■■■■■■■■■■■■■\"\n",
        "\n",
        "! echo \"Openpose実行結果\"\n",
        "\n",
        "! ls -l ./openpose/output/openpose.avi"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IrnCtUv8XohO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# MMD自動トレースキット実行"
      ]
    },
    {
      "metadata": {
        "id": "l5-4naWjXqUo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "ここからは、キットを実際に実行していきます。\n",
        "まずは、下のセルを実行して、インストールがすべて完了しているか確認してください。\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "soBmKdn_KjW5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!ls -l ./openpose/README.md\n",
        "!ls -l ./FCRN-DepthPrediction-vmd/README.md\n",
        "!ls -l ./3d-pose-baseline-vmd/README.md\n",
        "!ls -l ./VMD-3d-pose-baseline-multi/README.md"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Dd1C8N7iL4ZJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**【OK】**\n",
        "\n",
        "以下のように、ファイル名とファイルサイズが表示されていれば、インストール完了です。\n",
        "入力映像ファイルアップロードに進んでください。\n",
        "\n",
        "![インストール成功](https://drive.google.com/uc?export=view&id=1l13A2iF9oTpGcZSe9q8k7JyDyiABxOQT)\n",
        "\n",
        "---\n",
        "\n",
        "**【NG】**\n",
        "\n",
        "以下のように、「No such file or directory」と表示されている場合、インストール失敗です。\n",
        "\n",
        "![インストール失敗](https://drive.google.com/uc?export=view&id=1LuKoSMwFOzFg8NguFxqAtmQy9B1_KMXr)\n",
        "\n",
        "このノートブックの先頭に戻って初めから実行しなおいてください。\n",
        "\n",
        "３回やってもインストールに失敗する場合、ノートブックを共有してください。"
      ]
    },
    {
      "metadata": {
        "id": "4R8ogPNZXtQc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 入力映像ファイルアップロード"
      ]
    },
    {
      "metadata": {
        "id": "FrglOLBZXv9B",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "処理したい映像ファイルを、準備してください。\n",
        "\n",
        " - ファイル名は **半角英数字のみ** にしてください。\n",
        " - Googleドライブの **autotrace** フォルダ 直下に置いてください。\n",
        " - FPSは、**30fps** もしくは **60fps** にしてください。\n",
        " - 大きさは、**1280x720** にしてください。\n",
        " - 大きさもしくはFPSが指定通りではない場合、プログラム側で再エンコードします。（fpsは30になります）\n",
        " - **マウント後のGooleドライブ上のファイルの上書きや更新は正しく認識されません。** 新しいファイルは新規の名前でアップロードしてから処理して下さい。\n",
        " - 複数人数のトレースの場合、画面上から人物が消えると、並び順が取得できなくなるので、できるだけ取得したい人数分全員が映っているようにしてください。\n",
        " - アップロードが完了したら、下のセルを順次実行して下さい。"
      ]
    },
    {
      "metadata": {
        "id": "WQxj2Y6-Zutl",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@markdown ### 【O】入力映像ファイル\n",
        "#@markdown 解析対象となる映像のファイルの名前を入力して下さい。\n",
        "#@markdown 横幅が1280ではない、もしくは30fpsではない場合、再エンコードします。\n",
        "input_video_name = \"input.mp4\"  #@param {type: \"string\"}\n",
        "\n",
        "from google.colab import drive\n",
        "import os\n",
        "import cv2\n",
        "import datetime\n",
        "\n",
        "# Googleドライブマウント\n",
        "drive.mount('/gdrive')\n",
        "\n",
        "# 起点ディレクトリ\n",
        "base_path = \"/gdrive/My Drive/autotrace\"\n",
        "\n",
        "! echo \"autotraceフォルダの中身 -----------\"\n",
        "! ls -l \"$base_path\"\n",
        "! echo \"--------------------\"\n",
        "\n",
        "# 入力動画ファイル\n",
        "input_video = base_path + \"/\"+ input_video_name\n",
        "\n",
        "print(\"ファイル名: \", os.path.basename(input_video))\n",
        "print(\"ファイルサイズ: \", os.path.getsize(input_video))\n",
        "\n",
        "\n",
        "video = cv2.VideoCapture(input_video)\n",
        "# 幅\n",
        "W = video.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
        "# 高さ\n",
        "H = video.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
        "# 総フレーム数\n",
        "count = video.get(cv2.CAP_PROP_FRAME_COUNT)\n",
        "# fps\n",
        "fps = video.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "print(\"横: {0}, 縦: {1}, フレーム数: {2}, fps: {3}\".format(W, H, count, fps))\n",
        "\n",
        "\n",
        "\n",
        "width = 1280\n",
        "height = 720\n",
        "\n",
        "if W != 1280 or (fps != 30 and fps != 60):\n",
        "    print(\"大きさもしくはfpsが処理対象外のため、再エンコードします: \"+ input_video)\n",
        "    \n",
        "    # 縮尺\n",
        "    scale = width / W\n",
        "    \n",
        "    # 高さ\n",
        "    height = int(H * scale)\n",
        "\n",
        "    # 出力ファイルパス\n",
        "    out_name = 'recode_{0}.avi'.format(\"{0:%Y%m%d_%H%M%S}\".format(datetime.datetime.now()))\n",
        "    out_path = '{0}/{1}'.format(base_path, out_name)\n",
        "    \n",
        "    try:\n",
        "        fourcc = cv2.VideoWriter_fourcc(*\"I420\")\n",
        "        out = cv2.VideoWriter(out_path, fourcc, 30.0, (width, height), True)\n",
        "        # 入力ファイル\n",
        "        cap = cv2.VideoCapture(input_video)\n",
        "\n",
        "        while(cap.isOpened()):\n",
        "            # 動画から1枚キャプチャして読み込む\n",
        "            flag, frame = cap.read()  # Capture frame-by-frame\n",
        "\n",
        "            # 動画が終わっていたら終了\n",
        "            if flag == False:\n",
        "                break\n",
        "\n",
        "            # 縮小\n",
        "            output_frame = cv2.resize(frame, (width, height))\n",
        "\n",
        "            # 出力\n",
        "            out.write(output_frame)\n",
        "\n",
        "        # 終わったら開放\n",
        "        out.release()\n",
        "    except Exception as e:\n",
        "        print(\"再エンコード失敗\", e)\n",
        "\n",
        "    cap.release()\n",
        "    cv2.destroyAllWindows()\n",
        "    \n",
        "    print('MMD入力用AVIファイル再生成', out_path)\n",
        "    input_video_name = out_name\n",
        "\n",
        "    # 入力動画ファイル再設定\n",
        "    input_video = base_path + \"/\"+ input_video_name\n",
        "    \n",
        "    video = cv2.VideoCapture(input_video)\n",
        "    # 幅\n",
        "    W = video.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
        "    # 高さ\n",
        "    H = video.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
        "    # 総フレーム数\n",
        "    count = video.get(cv2.CAP_PROP_FRAME_COUNT)\n",
        "    # fps\n",
        "    fps = video.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "    print(\"【再チェック】横: {0}, 縦: {1}, フレーム数: {2}, fps: {3}\".format(W, H, count, fps))\n",
        "\n",
        "    \n",
        "!echo \"入力映像ファイルは\" \"$input_video_name\" \"です。\"\n",
        "!echo \"\"\n",
        "!echo \"問題なければ、次へ進んで下さい。\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LXcgFDk-YDMB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "最後のファイル名が取得できていたら成功です。\n",
        "\n",
        "---\n",
        "**【OK】**\n",
        "\n",
        "ファイルの大きさとfpsが指定通りの場合、入力ファイルをそのまま扱います。\n",
        "\n",
        "![OK](https://drive.google.com/uc?export=view&id=1lvOhCAj99_NUNDb-wfRAxeu-o0Exth7v)\n",
        "\n",
        "----\n",
        "**【再エンコード】**\n",
        "\n",
        "ファイルの大きさとfpsが指定通りではない場合、再エンコードしたaviファイルを入力ファイルとして扱います。\n",
        "\n",
        "![再エンコード](https://drive.google.com/uc?export=view&id=1xEiy-pdeHWQpt4CLZePg9YT1_7U8bEqz)\n"
      ]
    },
    {
      "metadata": {
        "id": "AFlJGTLmFLXE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "パラメーターを設定して、自動トレースを実行して下さい。\n",
        "\n",
        " - 【O】… Openposeで使用するパラメーター\n",
        " - 【F】… FCRN-DepthPrediction-vmdで使用するパラメーター\n",
        " - 【V】… VMD-3d-pose-baseline-multiで使用するパラメーター"
      ]
    },
    {
      "metadata": {
        "id": "8qMeT79QYFeC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## パラメーター設定"
      ]
    },
    {
      "metadata": {
        "id": "FQ3yCAl8YI1o",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@markdown 映像をトレースする際のパラメーターを入力して、セルを実行して下さい。\n",
        "\n",
        "#@markdown --- \n",
        "\n",
        "#@markdown ### 【O】映像に映っている最大人数\n",
        "#@markdown 映像から取得したい人数を入力して下さい。\n",
        "#@markdown 可能な限りこの人数分映っているように、映像データを加工しておいてください。\n",
        "number_people_max = 1  #@param {type: \"number\"}\n",
        "\n",
        "#@markdown --- \n",
        "\n",
        "#@markdown ### 【O】解析を開始するフレーム\n",
        "#@markdown 解析を開始するフレームNoを入力して下さい。(0始まり)\n",
        "#@markdown 最初にロゴが表示されている等、人体が正確にトレースできない場合に、全員が映像内に映っている最初のフレームを指定してください。\n",
        "frame_first = 0  #@param {type: \"number\"}\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown ### 【F】反転フレームリスト\n",
        "#@markdown Openposeが誤認識して反転しているフレーム番号(0始まり)を指定してください。\n",
        "#@markdown ここで指定された番号のフレームに対して、反転判定を行い、反転認定された場合、関節位置が反転されます。\n",
        "#@markdown カンマで複数件指定可能です。また、ハイフンで範囲が指定可能です。\n",
        "#@markdown 例）4,10-12　…　4,10,11,12 が反転判定対象フレームとなります。\n",
        "#@markdown デフォルトで、全フレームが反転判定対象となるよう設定しています。\n",
        "#@markdown 不要な回転等があった場合には、そのフレームをリストから除いて指定すると、回転がなくなる可能性があります。\n",
        "#@markdown 例）0-1112,1120-10000　…　1113-1119Fの間だけ、反転判定対象から除きます\n",
        "reverse_frames = \"0-100000\"  #@param {type: \"string\"}\n",
        "\n",
        "#@markdown --- \n",
        "\n",
        "#@markdown ### 【F】順番指定リスト\n",
        "#@markdown 複数人数トレースで、交差後の人物INDEX順番を指定してください。1人トレースの場合は空欄のままで大丈夫です。\n",
        "#@markdown Openposeが0F目で認識した順番に0, 1, とINDEXが割り当てられます。\n",
        "#@markdown フォーマット：［＜フレーム番号＞:0番目に推定された人物のインデックス,1番目に推定された人物のインデックス, …］\n",
        "#@markdown 例）[10:1,0]　…　10F目は、左から1番目の人物、0番目の人物の順番に並べ替えます。\n",
        "#@markdown message.logに上記フォーマットで、どのような順番で出力したかを残しているので、それを参考にしてください。\n",
        "#@markdown [10:1,0][30:0,1]のように、カッコ単位で複数件指定可能です。\n",
        "#@markdown また、output_XXX.aviでは、推定された順番に人物に色が割り当てられています。体の右半分は赤、左半分は以下の色になります。\n",
        "#@markdown 0:緑, 1:青, 2:白, 3:黄, 4:桃,  5:水色, 6:濃緑, 7:濃青, 8:灰色, 9:濃黄, 10:濃桃, 11:濃水色\n",
        "order_specific = \"\"  #@param {type: \"string\"}\n",
        "\n",
        "#@markdown --- \n",
        "\n",
        "#@markdown ### 【V】ボーン構造CSVファイル\n",
        "#@markdown トレース対象モデルのボーン構造CSVファイルのパスを選択もしくは入力して下さい。\n",
        "#@markdown あにまさ式ミクと、あにまさ式ミク準標準が選べる他、任意のモデルのボーン構造CSVファイルが入力可能です。\n",
        "#@markdown 任意のモデルボーン構造CSVファイルを入力する場合、Googleドライブの \"autotrace\" フォルダにcsvファイルをアップロードしてください。\n",
        "#@markdown そして「/gdrive/My Drive/autotrace/[csvファイル名]」のように入力して下さい。\n",
        "born_model_csv = \"born/\\u3042\\u306B\\u307E\\u3055\\u5F0F\\u30DF\\u30AF\\u30DC\\u30FC\\u30F3.csv\" #@param [\"born/\\u3042\\u306B\\u307E\\u3055\\u5F0F\\u30DF\\u30AF\\u30DC\\u30FC\\u30F3.csv\", \"born/\\u3042\\u306B\\u307E\\u3055\\u5F0F\\u30DF\\u30AF\\u6E96\\u6A19\\u6E96\\u30DC\\u30FC\\u30F3.csv\"] {allow-input: true}\n",
        "\n",
        "\n",
        "#@markdown --- \n",
        "\n",
        "#@markdown ### 【V】IKで出力するか\n",
        "#@markdown 足をIKで出力するか、yes か no を選んで下さい。\n",
        "#@markdown no を入力した場合、FKで出力します\n",
        "ik_flag = \"yes\"  #@param ['yes', 'no']\n",
        "is_ik = 1 if ik_flag == \"yes\" else 0\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown ### 【V】踵位置補正\n",
        "#@markdown 踵のY軸補正値を数値(小数可)で入力して下さい。\n",
        "#@markdown マイナス値を入力すると地面に近付き、プラス値を入力すると地面から遠ざかります。\n",
        "#@markdown ある程度は自動で補正しますが、補正しきれない場合に、設定して下さい。\n",
        "heel_position = 0.0  #@param {type: \"number\"}\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown ### 【V】センターZ移動倍率\n",
        "#@markdown センターZ移動に掛ける倍率を数値(小数可)で入力して下さい。\n",
        "#@markdown 値が小さいほど、センターZ移動の幅が小さくなります。\n",
        "#@markdown 0を入力した場合、センターZ軸移動を行いません。\n",
        "center_z_scale = 5  #@param {type: \"number\"}\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown ### 【V】滑らかさ\n",
        "#@markdown モーションの円滑化の度数を指定します\n",
        "#@markdown 1以上の整数のみを入力して下さい。\n",
        "#@markdown 度数が大きいほど、円滑化されます。（代わりに動作が小さくなります）\n",
        "smooth_times = 1  #@param {type: \"number\"}\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown ### 【V】移動間引き量\n",
        "#@markdown 移動キー（IK・センター）の間引きに使用する移動量を数値(小数可)で指定します\n",
        "#@markdown 指定された範囲内の移動があった場合に間引きされます。\n",
        "#@markdown 移動間引き量を0にした場合、間引きを行いません。\n",
        "threshold_pos = 0.5  #@param {type: \"number\"}\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown ### 【V】回転間引き角度\n",
        "#@markdown 回転キーの間引きに使用する角度(0～180度まで小数可)を指定します\n",
        "#@markdown 指定された角度以内の回転があった場合に間引きされます。\n",
        "threshold_rot = 3  #@param {type: \"number\"}\n",
        "\n",
        "\n",
        "\n",
        "!echo 映像に映っている最大人数: \"$number_people_max\"\n",
        "!echo 解析を開始するフレーム: \"$frame_first\"\n",
        "!echo 反転フレームリスト: \"$reverse_frames\"\n",
        "!echo 順番指定リスト: \"$order_specific\"\n",
        "!echo ボーン構造CSVファイル: \"$born_model_csv\"\n",
        "!echo IKで出力するか: \"$ik_flag\"\n",
        "!echo 踵位置補正: \"$heel_position\"\n",
        "!echo センターZ移動倍率: \"$center_z_scale\"\n",
        "!echo 滑らかさ: \"$smooth_times\"\n",
        "!echo 移動間引き量: \"$threshold_pos\"\n",
        "!echo 回転間引き角度: \"$threshold_rot\"\n",
        "\n",
        "!echo \"\"\n",
        "!echo 上記で間違いない場合、次に進んで下さい。"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SFWBO6c0YLa4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 自動トレース実行（全実行）"
      ]
    },
    {
      "metadata": {
        "id": "Zz0bFW4CYQJ9",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@markdown フォームの入力がすべて完了したら、このセルを実行してください。\n",
        "#@markdown 以下の順番で処理が実行されます。\n",
        "\n",
        "#@markdown 1. Openpose（映像→2D）\n",
        "#@markdown 2. FCRN-DepthPrediction-vmd（深度推定）\n",
        "#@markdown 3. 3d-pose-baseline-vmd（2D→3D）\n",
        "#@markdown 4. VMD-3d-pose-baseline-multi（3D→VMD）\n",
        "\n",
        "#@markdown トレース人数にもよりますが、6000Fで大体50～60分くらいかかります\n",
        "#@markdown Openposeが開始すると、しばらく細長い四角が出たまま動かなくなったように見えます。\n",
        "#@markdown 背後で処理は行われていますので、何も操作せずお待ちください。\n",
        "#@markdown vmdファイルが生成されていない、pos.txtの中身が空、error.txtだけがある、といった場合は、まずerror.txtの中身を確認して、「エラーが起きた場合」セクションを確認・実行して下さい。\n",
        "\n",
        "import time\n",
        "import datetime\n",
        "import cv2\n",
        "from google.colab import drive\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "# 出力フォルダ削除\n",
        "if os.path.exists(\"./output\"):\n",
        "    !rm -r ./output\n",
        "\n",
        "# 処理日時\n",
        "now_str = \"{0:%Y%m%d_%H%M%S}\".format(datetime.datetime.now())\n",
        "\n",
        "# Googleドライブマウント\n",
        "drive.mount('/gdrive')\n",
        "\n",
        "# 起点ディレクトリ\n",
        "drive_base_dir = \"/gdrive/My Drive/autotrace\"\n",
        "\n",
        "output_json = \"/content/output/json\"\n",
        "output_openpose_avi = \"/content/output/openpose.avi\"\n",
        "! mkdir -p \"$output_json\"\n",
        "\n",
        "# 出力用Googleドライブフォルダ\n",
        "drive_dir_path = drive_base_dir + \"/\" + now_str \n",
        "! mkdir -p \"$drive_dir_path\"\n",
        "\n",
        "! echo ------------------------------------------\n",
        "! echo Openpose\n",
        "! echo ------------------------------------------\n",
        "\n",
        "# Openpose実行\n",
        "! cd openpose/ && ./build/examples/openpose/openpose.bin --video \"$input_video\" --display 0 --model_pose COCO --write_json \"$output_json\" --write_video \"$output_openpose_avi\" --frame_first \"$frame_first\" --number_people_max \"$number_people_max\"\n",
        "\n",
        "! echo ------------------------------------------\n",
        "! echo FCRN-DepthPrediction-vmd\n",
        "! echo ------------------------------------------\n",
        "\n",
        "! cd FCRN-DepthPrediction-vmd && python tensorflow/predict_video.py --model_path tensorflow/data/NYU_FCRN.ckpt --video_path \"$input_video\" --json_path \"$output_json\" --interval 10 --reverse_frames \"$reverse_frames\" --order_specific \"$order_specific\" --verbose 1 --now \"$now_str\" --avi_output \"yes\"  --number_people_max \"$number_people_max\"\n",
        "    \n",
        "# 深度結果コピー\n",
        "depth_dir_path =  output_json + \"_\" + now_str + \"_depth\"\n",
        "\n",
        "if os.path.exists( depth_dir_path + \"/error.txt\"):\n",
        "    \n",
        "    # エラー発生\n",
        "    ! cp \"$depth_dir_path\"/error.txt \"$drive_dir_path\"\n",
        "\n",
        "    ! echo \"■■■■■■■■■■■■■■■■■■■■■■■■\"\n",
        "    ! echo \"■■エラーが発生したため、処理を中断しました。\"\n",
        "    ! echo \"■■\"\n",
        "    ! echo \"■■■■■■■■■■■■■■■■■■■■■■■■\"\n",
        "\n",
        "    ! echo \"$drive_dir_path\" \"の error.txt の中身を確認してください。\"\n",
        "\n",
        "else:\n",
        "    \n",
        "    ! cp \"$depth_dir_path\"/*.avi \"$drive_dir_path\"\n",
        "    ! cp \"$depth_dir_path\"/message.log \"$drive_dir_path\"\n",
        "    ! cp \"$depth_dir_path\"/reverse_frames.txt \"$drive_dir_path\"\n",
        "    ! cp \"$depth_dir_path\"/order_specific.txt \"$drive_dir_path\"\n",
        "\n",
        "    for i in range(1, number_people_max+1):\n",
        "        ! echo ------------------------------------------\n",
        "        ! echo 3d-pose-baseline-vmd [\"$i\"]\n",
        "        ! echo ------------------------------------------\n",
        "\n",
        "        target_name = \"_\" + now_str + \"_idx0\" + str(i)\n",
        "        target_dir = output_json + target_name\n",
        "\n",
        "        !cd ./3d-pose-baseline-vmd && python src/openpose_3dpose_sandbox_vmd.py --camera_frame --residual --batch_norm --dropout 0.5 --max_norm --evaluateActionWise --use_sh --epochs 200 --load 4874200 --gif_fps 30 --verbose 1 --openpose \"$target_dir\" --person_idx 1    \n",
        "\n",
        "        ! echo ------------------------------------------\n",
        "        ! echo VMD-3d-pose-baseline-multi [\"$i\"]\n",
        "        ! echo ------------------------------------------\n",
        "\n",
        "        ! cd ./VMD-3d-pose-baseline-multi && python applications/pos2vmd_multi.py -v 2 -t \"$target_dir\" -b \"$born_model_csv\" -c 30 -z \"$center_z_scale\" -s \"$smooth_times\" -p \"$threshold_pos\" -r \"$threshold_rot\" -k \"$is_ik\" -e \"$heel_position\"\n",
        "\n",
        "        # INDEX別結果コピー\n",
        "        idx_dir_path = drive_dir_path + \"/idx0\" + str(i)\n",
        "        ! mkdir -p \"$idx_dir_path\"\n",
        "        ! cp \"$target_dir\"/*.vmd \"$idx_dir_path\"\n",
        "        ! cp \"$target_dir\"/pos.txt \"$idx_dir_path\"\n",
        "\n",
        "    # Googleドライブ再マウント\n",
        "    drive.mount('/gdrive')\n",
        "\n",
        "    elapsed_time = (time.time() - start_time) / 60\n",
        "\n",
        "    ! echo \"■■■■■■■■■■■■■■■■■■■■■■■■\"\n",
        "    ! echo \"■■すべての処理が終了しました\"\n",
        "    ! echo \"■■\"\n",
        "    ! echo \"■■処理にかかった時間：\" \"$elapsed_time\" \"分\"\n",
        "    ! echo \"■■■■■■■■■■■■■■■■■■■■■■■■\"\n",
        "\n",
        "    ! echo \"\"\n",
        "    ! echo \"MMD自動トレース実行結果\"\n",
        "\n",
        "    ! echo \"$drive_dir_path\"\n",
        "    ! ls -l \"$drive_dir_path\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EQUcMLsf3TcN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 自動トレース再実行(深度推定以降)"
      ]
    },
    {
      "metadata": {
        "id": "yM2PNPpd3uai",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@markdown Openposeの処理が終わっていて、【F】【V】のパラメーターを調整して再実行したい場合\n",
        "\n",
        "#@markdown 1. 「パラメーター設定」の【F】【V】のパラメーターを埋める\n",
        "#@markdown 2. 「パラメーター設定」のセルを実行する\n",
        "#@markdown 3. このセルを実行する\n",
        "\n",
        "#@markdown 新しいパラメーターで、FCRN-DepthPrediction-vmd（深度推定）以降のみが実行されます。\n",
        "#@markdown トレース元動画や【O】のパラメーターを変えたい場合、「入力映像ファイルアップロード」からすべて再実行してください。\n",
        "\n",
        "import time\n",
        "import datetime\n",
        "import cv2\n",
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "# 処理日時\n",
        "now_str = \"{0:%Y%m%d_%H%M%S}\".format(datetime.datetime.now())\n",
        "\n",
        "# Googleドライブマウント\n",
        "drive.mount('/gdrive')\n",
        "\n",
        "# 起点ディレクトリ\n",
        "drive_base_dir = \"/gdrive/My Drive/autotrace\"\n",
        "\n",
        "output_json = \"/content/output/json\"\n",
        "output_openpose_avi = \"/content/output/openpose.avi\"\n",
        "\n",
        "# 出力用Googleドライブフォルダ\n",
        "drive_dir_path = drive_base_dir + \"/\" + now_str \n",
        "! mkdir -p \"$drive_dir_path\"\n",
        "\n",
        "! echo ------------------------------------------\n",
        "! echo FCRN-DepthPrediction-vmd\n",
        "! echo ------------------------------------------\n",
        "\n",
        "! cd FCRN-DepthPrediction-vmd && python tensorflow/predict_video.py --model_path tensorflow/data/NYU_FCRN.ckpt --video_path \"$input_video\" --json_path \"$output_json\" --interval 10 --reverse_frames \"$reverse_frames\" --order_specific \"$order_specific\" --verbose 1 --now \"$now_str\" --avi_output \"yes\"  --number_people_max \"$number_people_max\"\n",
        "    \n",
        "# 深度結果コピー\n",
        "depth_dir_path =  output_json + \"_\" + now_str + \"_depth\"\n",
        "\n",
        "if os.path.exists( depth_dir_path + \"/error.txt\"):\n",
        "    \n",
        "    # エラー発生\n",
        "    ! cp \"$depth_dir_path\"/error.txt \"$drive_dir_path\"\n",
        "\n",
        "    ! echo \"■■■■■■■■■■■■■■■■■■■■■■■■\"\n",
        "    ! echo \"■■エラーが発生したため、処理を中断しました。\"\n",
        "    ! echo \"■■\"\n",
        "    ! echo \"■■■■■■■■■■■■■■■■■■■■■■■■\"\n",
        "\n",
        "    ! echo \"$drive_dir_path\" \"の error.txt の中身を確認してください。\"\n",
        "\n",
        "else:\n",
        "    \n",
        "    ! cp \"$depth_dir_path\"/*.avi \"$drive_dir_path\"\n",
        "    ! cp \"$depth_dir_path\"/message.log \"$drive_dir_path\"\n",
        "    ! cp \"$depth_dir_path\"/reverse_frames.txt \"$drive_dir_path\"\n",
        "    ! cp \"$depth_dir_path\"/order_specific.txt \"$drive_dir_path\"\n",
        "\n",
        "    for i in range(1, number_people_max+1):\n",
        "        ! echo ------------------------------------------\n",
        "        ! echo 3d-pose-baseline-vmd [\"$i\"]\n",
        "        ! echo ------------------------------------------\n",
        "\n",
        "        target_name = \"_\" + now_str + \"_idx0\" + str(i)\n",
        "        target_dir = output_json + target_name\n",
        "\n",
        "        !cd ./3d-pose-baseline-vmd && python src/openpose_3dpose_sandbox_vmd.py --camera_frame --residual --batch_norm --dropout 0.5 --max_norm --evaluateActionWise --use_sh --epochs 200 --load 4874200 --gif_fps 30 --verbose 1 --openpose \"$target_dir\" --person_idx 1    \n",
        "\n",
        "        ! echo ------------------------------------------\n",
        "        ! echo VMD-3d-pose-baseline-multi [\"$i\"]\n",
        "        ! echo ------------------------------------------\n",
        "\n",
        "        ! cd ./VMD-3d-pose-baseline-multi && python applications/pos2vmd_multi.py -v 2 -t \"$target_dir\" -b \"$born_model_csv\" -c 30 -z \"$center_z_scale\" -s \"$smooth_times\" -p \"$threshold_pos\" -r \"$threshold_rot\" -k \"$is_ik\" -e \"$heel_position\"\n",
        "\n",
        "        # INDEX別結果コピー\n",
        "        idx_dir_path = drive_dir_path + \"/idx0\" + str(i)\n",
        "        ! mkdir -p \"$idx_dir_path\"\n",
        "        ! cp \"$target_dir\"/*.vmd \"$idx_dir_path\"\n",
        "        ! cp \"$target_dir\"/pos.txt \"$idx_dir_path\"\n",
        "\n",
        "    # Googleドライブ再マウント\n",
        "    drive.mount('/gdrive')\n",
        "\n",
        "    elapsed_time = (time.time() - start_time) / 60\n",
        "\n",
        "    ! echo \"■■■■■■■■■■■■■■■■■■■■■■■■\"\n",
        "    ! echo \"■■すべての処理が終了しました\"\n",
        "    ! echo \"■■\"\n",
        "    ! echo \"■■処理にかかった時間：\" \"$elapsed_time\" \"分\"\n",
        "    ! echo \"■■■■■■■■■■■■■■■■■■■■■■■■\"\n",
        "\n",
        "    ! echo \"\"\n",
        "    ! echo \"MMD自動トレース実行結果\"\n",
        "\n",
        "    ! echo \"$drive_dir_path\"    \n",
        "    ! ls -l \"$drive_dir_path\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tQh07oDkDCz0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 自動トレース再実行(VMDのみ)"
      ]
    },
    {
      "metadata": {
        "id": "FULbLzXfyJ2W",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@markdown 【V】（VMDのパラメーター）だけを調整して再実行したい場合\n",
        "\n",
        "#@markdown 1. 「パラメーター設定」の【V】のパラメーターを埋める\n",
        "#@markdown 2. 「パラメーター設定」のセルを実行する\n",
        "#@markdown 3. このセルの「INDEX番号」欄を入力する\n",
        "#@markdown 4. このセルを実行する\n",
        "\n",
        "#@markdown 新しいパラメーターと指定されたINDEXで、VMD-3d-pose-baseline-multi（3D→VMD）のみが実行されます。\n",
        "#@markdown **Googleドライブに出力されたidxフォルダを再利用しますので、削除しないでください。**\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown ### INDEX番号\n",
        "#@markdown 処理を実行したいINDEXの番号のみを入力して下さい。\n",
        "i = 1  #@param {type: \"number\"}\n",
        "\n",
        "import time\n",
        "import datetime\n",
        "import cv2\n",
        "from google.colab import drive\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "# Googleドライブマウント\n",
        "drive.mount('/gdrive')\n",
        "\n",
        "# 起点ディレクトリ\n",
        "drive_base_dir = \"/gdrive/My Drive/autotrace\"\n",
        "\n",
        "output_json = \"/content/output/json\"\n",
        "output_openpose_avi = \"/content/output/openpose.avi\"\n",
        "\n",
        "# 出力用Googleドライブフォルダ\n",
        "drive_dir_path = drive_base_dir + \"/\" + now_str \n",
        "! mkdir -p \"$drive_dir_path\"\n",
        "\n",
        "target_name = \"_\" + now_str + \"_idx0\" + str(i)\n",
        "target_dir = output_json + target_name\n",
        "\n",
        "! echo ------------------------------------------\n",
        "! echo VMD-3d-pose-baseline-multi [\"$i\"]\n",
        "! echo ------------------------------------------\n",
        "\n",
        "! cd ./VMD-3d-pose-baseline-multi && python applications/pos2vmd_multi.py -v 2 -t \"$target_dir\" -b \"$born_model_csv\" -c 30 -z \"$center_z_scale\" -s \"$smooth_times\" -p \"$threshold_pos\" -r \"$threshold_rot\" -k \"$is_ik\" -e \"$heel_position\"\n",
        "\n",
        "# INDEX別結果コピー\n",
        "idx_dir_path = drive_dir_path + \"/idx0\" + str(i)\n",
        "! mkdir -p \"$idx_dir_path\"\n",
        "! cp \"$target_dir\"/*.vmd \"$idx_dir_path\"\n",
        "! cp \"$target_dir\"/pos.txt \"$idx_dir_path\"\n",
        "\n",
        "# Googleドライブ再マウント\n",
        "drive.mount('/gdrive')\n",
        "    \n",
        "elapsed_time = (time.time() - start_time) / 60\n",
        "    \n",
        "! echo \"■■■■■■■■■■■■■■■■■■■■■■■■\"\n",
        "! echo \"■■すべての処理が終了しました\"\n",
        "! echo \"■■\"\n",
        "! echo \"■■処理にかかった時間：\" \"$elapsed_time\" \"分\"\n",
        "! echo \"■■■■■■■■■■■■■■■■■■■■■■■■\"\n",
        "\n",
        "! echo \"\"\n",
        "! echo \"MMD自動トレース実行結果\"\n",
        "\n",
        "! echo \"$idx_dir_path\"\n",
        "! ls -l \"$idx_dir_path\"/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UzsQ7HrjphVF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# エラーが起きた場合"
      ]
    },
    {
      "metadata": {
        "id": "_JiZw2Ott1Rr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "エラーが起きた場合、vmdファイルが生成されていない場合は、このセクションを上からひとつずつ実行してください。\n",
        "\n",
        "それでも解決しない場合、導入編の手順に従って、ノートブックのコピーを共有してください。"
      ]
    },
    {
      "metadata": {
        "id": "1uUbtOC7ptjz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 1. Openposeが読み取る最初のフレームに、人数分映っていない場合"
      ]
    },
    {
      "metadata": {
        "id": "Mw8zNO_yG-Nt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "error.txtに「最初のフレームに人数分のデータがありません。」と記載されている場合、Openposeが読み取る最初のフレームに人数分のデータがない事が原因です。\n",
        "\n",
        "下のセルを実行してください。"
      ]
    },
    {
      "metadata": {
        "id": "ppAVzFJzn4vh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!find output/json/ -name \"*.json\" | sort | head -n 1 | xargs ls -l\n",
        "!find output/json/ -name \"*.json\" | sort | head -n 1 | xargs cat"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4e-MYAS-uLEx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "【状況】\n",
        "下記のように、peopleの後ろにデータがない場合、0F目に人物データが取得できていません。\n",
        "\n",
        "![結果なし](https://drive.google.com/uc?export=view&id=1osssF0NCWply6J0-zPIhN2wm1gT0o6Io)\n",
        "\n",
        "【解決方法】\n",
        "\n",
        "人物が映っている最初のフレームを「【O】解析を開始するフレーム」に指定してください。\n",
        "\n",
        "「Openposeが読み取ったフレームリスト30件」のセルを実行すると、先頭30件のOpenpose結果ファイルが表示されます。\n",
        "\n",
        "![先頭30件](https://drive.google.com/uc?export=view&id=1lxP78w4NIbQSKWhpfbynCjDKOgmcNp0o)\n",
        "\n",
        "人物データがないJSONファイルは、ファイルサイズがとても小さいです。（図の場合、0F目が人物データなし）\n",
        "\n",
        "1人分のデータで大体500Byte前後(0.5KB)のファイルサイズになります。\n",
        "\n",
        "これを参考にして、先頭のフレーム番号を決めてください。元動画の編集や再アップロードは不要です。\n",
        "\n",
        "先頭のフレーム番号が決まったら、「パラメーター設定」セクションの「【O】解析を開始するフレーム」に、その番号を入力して、「パラメーター設定」＞「自動トレース実行（全実行）」の順で実行してください。\n",
        "\n",
        "\n",
        "複数人トレースの場合は、0F目（【O】解析を開始するフレーム）には全員映っている必要があります。\n",
        "ファイルサイズも人数分増えますので、目安にしてください。"
      ]
    },
    {
      "metadata": {
        "id": "cYIc5neP9oAl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 2. Openposeが読み取ったフレームリスト先頭30件"
      ]
    },
    {
      "metadata": {
        "id": "qT0qOAp09xlM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ls -l output/json/*.json | head -n 30"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NCckdf_gp0F2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 3. Googleドライブにファイルが追加されない場合"
      ]
    },
    {
      "metadata": {
        "id": "wWIauqkWq15H",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "error.txt もvmdも何も出力されなかった場合、セルの出力結果を確認してください。\n",
        "\n",
        "最後にファイル名のリストが出ている場合、出力自体は成功しています。\n",
        "\n",
        "ただ、Googleドライブとの連携が済んでいるにも関わらず、データが反映されないケースを確認しています。\n",
        "\n",
        "詳細は調査中ですが、とりあえずの対応として、クラウド上の元データをダウンロードしてください。\n",
        "\n",
        "1. 目次の横にある「ファイル」欄をクリックする\n",
        "2. ヘッダの「更新」をクリックする\n",
        "3. output ＞ json を開く\n",
        "4. xxx_depth ＞ output_XXX.avi …　背景AVI(MMD)\n",
        "5. xxx_idxXX ＞ output_XXX.vmd　…　モーションデータ(MMD)\n",
        "6. xxx_idxXX ＞ pos.txt　…　3D関節位置データ(Unity)\n",
        "7. 複数人数のトレースした場合、idxが複数件できています。\n",
        "\n",
        "![クラウドデータ](https://drive.google.com/uc?export=view&id=1fArRyRdfs1kBLaLTpdkdJ-MYwHNe-UUq)\n"
      ]
    },
    {
      "metadata": {
        "id": "iOLiarVDw_TY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# TIPS"
      ]
    },
    {
      "metadata": {
        "id": "oiVbKfOVxByH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "上記の他、思いつくままに、参考になりそうな事を。"
      ]
    },
    {
      "metadata": {
        "id": "RS2M0r4vFH5Z",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## オススメの作業順番"
      ]
    },
    {
      "metadata": {
        "id": "ESNt5KETxMqv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "私は以下の順番で作業を行っています。\n",
        "\n",
        "1. 「【O】映像に映っている最大人数」に、トレース元動画からトレースしたい人数を入力して、セルを実行する\n",
        "2. 「自動トレース実行（全実行）」のセルを実行する\n",
        "3. 結果がエラーになった場合、「エラーが起きた場合」の「Openposeが読み取る最初のフレームに、人数分映っているか」を実行して、人物が映っているフレームを確認する。成功していたら6に移動。\n",
        "4. 「【O】解析を開始するフレーム」に、3で見つけたフレーム番号を入力する\n",
        "5. 「パラメーター設定」のセルを実行する\n",
        "6. 「自動トレース再実行(深度推定以降)」のセルを実行する\n",
        "7.  意図しない回転があった場合、「【F】反転フレームリスト」に該当フレームを除いて設定する\n",
        "8. 複数人数のトレースで、入れ替わりが認識できていない場合、message.logを見ながら、「【F】順番指定リスト」に順番を指定する\n",
        "9. 「パラメーター設定」のセルを実行する\n",
        "10. 「自動トレース再実行(深度推定以降)」のセルを実行する\n",
        "11. 納得いくまで、7～10を繰り返す\n",
        "12. 回転や入れ替えの指定が完了したら、【V】のパラメーターを設定する\n",
        "13. 「パラメーター設定」のセルを実行する\n",
        "14. 「自動トレース再実行(VMDのみ)」のセルを実行する。複数人数のトレースの場合、人数分実行する\n",
        "15. 納得いくまで、12～14を繰り返す\n",
        "\n",
        "頑張って下さい！"
      ]
    },
    {
      "metadata": {
        "id": "AhrZcOhMxO2f",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## トレースしやすい動画"
      ]
    },
    {
      "metadata": {
        "id": "assKjr_XxRKL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        " - 固定カメラである\n",
        " - 関節がはっきり分かる\n",
        "    - ロングスカートや和服等、関節が見えにくい人体は苦手です\n",
        "    - 背景が人物と似た色である、影が濃く映っている、などの場合、トレースを間違える事が多いです\n",
        "    - 手首・足首まで映っている方が、精度が高くなります\n",
        " - 最初のフレームで前向きである\n",
        "   - 後ろや横を向いていると始めのデータが綺麗に取れません（一度正面を向いてくれると直る事が多いです）\n",
        " - 最初のフレームで全身の関節が判別できる\n",
        "   - どこか隠れていると、それだけ精度が落ちます\n",
        " - 頭が上、足が下\n",
        "   - 逆立ちやキックなどで高く足が上がっている場合、足を手と誤認識します。\n"
      ]
    }
  ]
}