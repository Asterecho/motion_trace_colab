{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AutoTrace.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "NxA42Uase5hk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# MMD自動トレースキット準備"
      ]
    },
    {
      "metadata": {
        "id": "aCQg_tD0e9v0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "このノートブックでは、MMD自動トレースの準備と実行を行います。"
      ]
    },
    {
      "metadata": {
        "id": "F8qp5VzAWyGl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## ランタイムをGPUに変更"
      ]
    },
    {
      "metadata": {
        "id": "UNrlmW0-W1D1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "ヘッダの \"ランタイム\"　＞　\"ランタイムのタイプを変更\"　＞　\"GPU\"　を選択して下さい。\n",
        "\n",
        "変更できたら、下のセルを実行して下さい。"
      ]
    },
    {
      "metadata": {
        "id": "P3zDmyRDwRs0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "! nvcc --version\n",
        "! nvidia-smi"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oo-BfaAdw9cN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "下記のように表示されていたら成功です。\n",
        "\n",
        "![GPU変更成功](https://drive.google.com/uc?export=view&id=17CG697kiTLkwVOdH1wg2W3MSB-hyi9u5)\n",
        "\n",
        "下記のように表示されていたら、ランタイムの変更に失敗しているので、再度確認してください。\n",
        "\n",
        "![GPU切り替え失敗](https://drive.google.com/uc?export=view&id=1tufSuT7ocWxv3HkrmA5kwlemhu0gv6Je)"
      ]
    },
    {
      "metadata": {
        "id": "38aL3FiVWvmN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 準備開始"
      ]
    },
    {
      "metadata": {
        "id": "6k716wWUxT4F",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "画面左上の「＞」をクリックして下さい。目次が開きます。\n",
        "\n",
        "![目次](https://drive.google.com/uc?export=view&id=1x8AdFNmsIQPrtYptBf_NXPRNBJF8ON8z)\n",
        "\n",
        "目次の「MMD自動トレースキット実行」を選択して下さい。\n",
        "\n",
        "![実行選択](https://drive.google.com/uc?export=view&id=1YaSrtio06mmu94RUkU5dSolNtFqPiAnV)\n",
        "\n",
        "ヘッダの　\"ランタイム\"　＞　\"より前のセルを実行\"　を選択すると、準備が開始されます。\n",
        "\n",
        "![すべてのセルを実行](https://drive.google.com/uc?export=view&id=1rIbVI_Qyjs8idEzkIR0IBIx6Dbp3te08)\n",
        "\n",
        "画面の一番下に、以下のように出力されれば、完了です。\n",
        "\n",
        "![処理成功](https://drive.google.com/uc?export=view&id=1D21xezv6QN0RQF5ZU_LR7PRnOk0Dw4Sc)\n",
        "\n",
        "大体40分くらいかかります。\n",
        "\n",
        "![処理失敗](https://drive.google.com/uc?export=view&id=1t-immeF3Ji1_GBNatZOG1C07j42de4Rq)\n",
        "\n",
        "最後の行に、「No such file or directory」と出力されていたら失敗です。\n",
        "\n",
        "解決方法が分からない場合、私までご連絡ください。"
      ]
    },
    {
      "metadata": {
        "id": "E-h6RWCXnZU8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 環境設定"
      ]
    },
    {
      "metadata": {
        "id": "IPiDvSBanScr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 処理時間計測のための開始時間\n",
        "import time\n",
        "start_time = time.time()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9UMIfs3snkRm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Openposeバージョンタグ\n",
        "ver_openpose = \"v1.4.0\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iWQcbt_rnblK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# キットバージョンタグ\n",
        "ver_tag = \"ver1.00\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EK-WUxgciv9V",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## cmake"
      ]
    },
    {
      "metadata": {
        "id": "djxuuJjKix5B",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "! wget -c \"https://github.com/Kitware/CMake/releases/download/v3.13.4/cmake-3.13.4.tar.gz\"\n",
        "! tar xf cmake-3.13.4.tar.gz\n",
        "! cd cmake-3.13.4 && ./configure && make && sudo make install"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Viqw8qJqfDyf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Openpose"
      ]
    },
    {
      "metadata": {
        "id": "a-fnE9kwgcfg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# ライブラリのインストール\n",
        "\n",
        "# Basic\n",
        "! sudo apt-get --assume-yes update\n",
        "! sudo apt-get --assume-yes install build-essential\n",
        "# OpenCV\n",
        "! sudo apt-get --assume-yes install libopencv-dev\n",
        "# General dependencies\n",
        "! sudo apt-get --assume-yes install libatlas-base-dev libprotobuf-dev libleveldb-dev libsnappy-dev libhdf5-serial-dev protobuf-compiler\n",
        "! sudo apt-get --assume-yes install --no-install-recommends libboost-all-dev\n",
        "# Remaining dependencies, 14.04\n",
        "! sudo apt-get --assume-yes install libgflags-dev libgoogle-glog-dev liblmdb-dev\n",
        "# Python2 libs\n",
        "! sudo apt-get --assume-yes install python-setuptools python-dev build-essential\n",
        "! sudo easy_install pip\n",
        "! sudo -H pip install --upgrade numpy protobuf opencv-python\n",
        "# Python3 libs\n",
        "! sudo apt-get --assume-yes install python3-setuptools python3-dev build-essential\n",
        "! sudo apt-get --assume-yes install python3-pip\n",
        "! sudo -H pip3 install --upgrade numpy protobuf opencv-python\n",
        "# OpenCV 2.4 -> Added as option\n",
        "# # sudo apt-get --assume-yes install libopencv-dev\n",
        "# OpenCL Generic\n",
        "! sudo apt-get --assume-yes install opencl-headers ocl-icd-opencl-dev\n",
        "! sudo apt-get --assume-yes install libviennacl-dev"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eMCKuBuagoFo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#  Openpose の clone\n",
        "! git clone  --depth 1 -b \"$ver_openpose\" https://github.com/CMU-Perceptual-Computing-Lab/openpose.git "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BSls4lfOgwG0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#  Openpose の モデルデータDL\n",
        "! cd openpose/models && ./getModels.sh"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8ld2HCrvg7c3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Openpose の ビルド\n",
        "! sed -i 's/execute_process(COMMAND git checkout master WORKING_DIRECTORY ${CMAKE_SOURCE_DIR}\\/3rdparty\\/caffe)/execute_process(COMMAND git checkout f019d0dfe86f49d1140961f8c7dec22130c83154 WORKING_DIRECTORY ${CMAKE_SOURCE_DIR}\\/3rdparty\\/caffe)/g' openpose/CMakeLists.txt\n",
        "! cd openpose && rm -r build || true && mkdir build && cd build && cmake .. && make -j`nproc` # example demo usage"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lZLayojmhDdI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## FCRN-DepthPrediction-vmd"
      ]
    },
    {
      "metadata": {
        "id": "rJw3lnjKhIp7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# FCRN-DepthPrediction-vmd の clone\n",
        "! git clone  --depth 1 -b \"$ver_tag\" https://github.com/miu200521358/FCRN-DepthPrediction-vmd.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sNbLo-sBhlcL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# FCRN-DepthPrediction-vmd の モデルデータDL\n",
        "\n",
        "# モデルデータ の導入\n",
        "! mkdir -p ./FCRN-DepthPrediction-vmd/tensorflow/data\n",
        "\n",
        "# モデルデータのダウンロード\n",
        "! cd  ./FCRN-DepthPrediction-vmd/tensorflow/data && wget -c \"http://campar.in.tum.de/files/rupprecht/depthpred/NYU_FCRN-checkpoint.zip\" && unzip NYU_FCRN-checkpoint.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Gvkd3YfCiVJ8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 3d-pose-baseline-vmd"
      ]
    },
    {
      "metadata": {
        "id": "w3Uh4e6liYPg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 3d-pose-baseline-vmd の clone\n",
        "! git clone  --depth 1 -b \"$ver_tag\" https://github.com/miu200521358/3d-pose-baseline-vmd.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Iw7kI9zhi_7k",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 3d-pose-baseline-vmd の Human3.6MモデルデータDL\n",
        "\n",
        "# Human3.6Mモデルデータ の導入\n",
        "! mkdir -p ./3d-pose-baseline-vmd/data\n",
        "\n",
        "# Human3.6Mモデルデータのダウンロード\n",
        "! cd  ./3d-pose-baseline-vmd/data && wget -c \"https://www.dropbox.com/s/e35qv3n6zlkouki/h36m.zip\" && unzip h36m.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dclND00zjGdN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 3d-pose-baseline-vmd の 学習データDL\n",
        "\n",
        "# 3d-pose-baseline用学習データ の導入\n",
        "! mkdir -p ./3d-pose-baseline-vmd/experiments\n",
        "\n",
        "# 3d-pose-baseline用学習データのダウンロード\n",
        "file_id = \"1v7ccpms3ZR8ExWWwVfcSpjMsGscDYH7_\"\n",
        "file_name = \"experiments.zip\"\n",
        "! cd  ./3d-pose-baseline-vmd && curl -sc ./cookie \"https://drive.google.com/uc?export=download&id=$file_id\" > /dev/null\n",
        "code = \"$(awk '/_warning_/ {print $NF}' ./cookie)\"  \n",
        "! cd  ./3d-pose-baseline-vmd && curl -Lb ./cookie \"https://drive.google.com/uc?export=download&confirm=$code&id=$file_id\" -o \"$file_name\"\n",
        "! cd  ./3d-pose-baseline-vmd && unzip experiments.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jruMP1J4jLXX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## VMD-3d-pose-baseline-multi"
      ]
    },
    {
      "metadata": {
        "id": "87ZPjj6IjPgj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# VMD-3d-pose-baseline-multi の clone\n",
        "\n",
        "! git clone  --depth 1 -b \"$ver_tag\" https://github.com/miu200521358/VMD-3d-pose-baseline-multi.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fnuSwMT9jW5E",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# VMD-3d-pose-baseline-multi のライブラリ\n",
        "\n",
        "! sudo apt-get install python3-pyqt5  \n",
        "! sudo apt-get install pyqt5-dev-tools\n",
        "! sudo apt-get install qttools5-dev-tools"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GIp8lIjZY7ih",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 準備結果確認"
      ]
    },
    {
      "metadata": {
        "id": "T8vXn_ZE6bHk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# サンプルの実行確認\n",
        "! cd openpose && ./build/examples/openpose/openpose.bin --video examples/media/video.avi --write_json ./output/ --display 0  --write_video ./output/openpose.avi"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gZjjbPz0llYs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "elapsed_time = (time.time() - start_time) / 60\n",
        "\n",
        "! echo \"■■■■■■■■■■■■■■■■■■■■■■■■\"\n",
        "! echo \"■■すべての処理が終了しました\"\n",
        "! echo \"■■\"\n",
        "! echo \"■■処理にかかった時間：\" \"$elapsed_time\" \"分\"\n",
        "! echo \"■■■■■■■■■■■■■■■■■■■■■■■■\"\n",
        "\n",
        "! echo \"Openpose実行結果\"\n",
        "\n",
        "! ls -l ./openpose/output/openpose.avi"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IrnCtUv8XohO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# MMD自動トレースキット実行"
      ]
    },
    {
      "metadata": {
        "id": "l5-4naWjXqUo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "ここからは、キットを実際に実行していきます。"
      ]
    },
    {
      "metadata": {
        "id": "4R8ogPNZXtQc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 入力映像ファイルアップロード"
      ]
    },
    {
      "metadata": {
        "id": "FrglOLBZXv9B",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "処理したい映像ファイルを、準備してください。\n",
        "\n",
        " - FPSは、30fpsに固定してください。\n",
        " - 解像度は、1280x720にしてください。\n",
        " - 複数人数のトレースの場合、画面上から人物が消えると、並び順が取得できなくなるので、できるだけ取得したい人数分全員が映っているようにしてください。\n",
        "\n",
        "準備が出来たら、Googleドライブの \"autotrace\" フォルダ に、半角英数字のファイル名でアップロードしてください。\n",
        "\n",
        "アップロードが終わったら、下のフォームにファイル名を入力してください。\n",
        "\n",
        "フォームの値を変更すると、左側のコード欄の値が変わりますが、そのままで大丈夫です。"
      ]
    },
    {
      "metadata": {
        "id": "r_9d7aWuX781",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@markdown ### 入力映像ファイル\n",
        "#@markdown 解析対象となる映像のファイルの名前を入力して下さい。\n",
        "#@markdown Googleドライブの \"autotrace\" フォルダ の直下に置いてください。\n",
        "input_video_name = \"input.mp4\"  #@param {type: \"string\"}\n",
        "\n",
        "!echo \"入力映像ファイルは\" \"$input_video_name\" \"で合っていますか？\"\n",
        "!echo \"問題なければ、次へ進んで下さい。\"\n",
        "!echo \"違う場合、ファイル名欄をもう一度確認してください。\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "abCgtWiiX--C",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "フォーム名が入力できたら、下のセルを実行して下さい。"
      ]
    },
    {
      "metadata": {
        "id": "vT6dDn5cYAzq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# Googleドライブマウント\n",
        "drive.mount('/gdrive')\n",
        "\n",
        "# 起点ディレクトリ\n",
        "base_path = \"/gdrive/My Drive/autotrace\"\n",
        "\n",
        "! echo \"autotraceフォルダの中身 -----------\"\n",
        "! ls -l \"$base_path\"\n",
        "! echo \"--------------------\"\n",
        "\n",
        "# 入力動画ファイル\n",
        "input_video = base_path + \"/\"+ input_video_name\n",
        "\n",
        "print(\"ファイル名: \", os.path.basename(input_video))\n",
        "print(\"ファイルサイズ: \", os.path.getsize(input_video))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LXcgFDk-YDMB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "最後のファイル名とファイルサイズが取得できていたら成功です。\n",
        "\n",
        "![input.mp4](https://drive.google.com/uc?export=view&id=174pRGkUR7PH5hDyzfsmYmzOrmftQxrbP)"
      ]
    },
    {
      "metadata": {
        "id": "8qMeT79QYFeC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## パラメーター設定"
      ]
    },
    {
      "metadata": {
        "id": "FQ3yCAl8YI1o",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown ### 解析を開始するフレーム\n",
        "#@markdown 解析を開始するフレームNoを入力して下さい。(0始まり)\n",
        "#@markdown 最初にロゴが表示されている等、人体が正確にトレースできない場合に、冒頭のフレームをスキップできます。\n",
        "frame_first = 0  #@param {type: \"number\"}\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown ### 映像に映っている最大人数\n",
        "#@markdown 映像から取得したい人数を入力して下さい。\n",
        "#@markdown 常にこの人数分映っているように、映像データを加工しておいてください。\n",
        "number_people_max = 1  #@param {type: \"number\"}\n",
        "\n",
        "#@markdown --- \n",
        "\n",
        "#@markdown ### 反転フレームリスト\n",
        "#@markdown Openposeが誤認識して反転しているフレーム番号(0始まり)を指定してください。\n",
        "#@markdown ここで指定された番号のフレームに対して、反転判定を行い、反転認定された場合、関節位置が反転されます。\n",
        "#@markdown カンマで複数件指定可能です。また、ハイフンで範囲が指定可能です。\n",
        "#@markdown 例）4,10-12　…　4,10,11,12 が反転判定対象フレームとなります。\n",
        "order_specific = \"0-10000\"  #@param {type: \"string\"}\n",
        "\n",
        "#@markdown --- \n",
        "\n",
        "#@markdown ### 順番指定リスト\n",
        "#@markdown 複数人数トレースで、交差後の人物INDEX順番を指定してください。\n",
        "#@markdown 0F目の立ち位置左から順番に0番目、1番目、と数えます。\n",
        "#@markdown フォーマット：［＜フレーム番号＞:左から0番目にいる人物のインデックス,左から1番目…］\n",
        "#@markdown 例）[10:1,0]　…　10F目は、左から1番目の人物、0番目の人物の順番に並べ替えます。\n",
        "#@markdown [10:1,0][30:0,1]のように、カッコ単位で複数件指定可能です。\n",
        "reverse_frames = \"\"  #@param {type: \"string\"}\n",
        "\n",
        "#@markdown --- \n",
        "\n",
        "#@markdown ### ボーン構造CSVファイル\n",
        "#@markdown トレース対象モデルのボーン構造CSVファイルのパスを入力して下さい。\n",
        "#@markdown Googleドライブの \"autotrace\" フォルダにアップロードしたcsvファイルも読み込めます。\n",
        "#@markdown その場合、「/gdrive/My Drive/autotrace/[csvファイル名]」のように入力して下さい。\n",
        "born_model_csv = \"born/あにまさ式ミク準標準ボーン.csv\"  #@param {type: \"string\"}\n",
        "\n",
        "#@markdown --- \n",
        "\n",
        "#@markdown ### IKで出力するか\n",
        "#@markdown 足をIKで出力するか、yes か no を選んで下さい。\n",
        "#@markdown no を入力した場合、FKで出力します\n",
        "ik_flag = \"yes\"  #@param ['yes', 'no']\n",
        "is_ik = 1 if ik_flag == \"yes\" else 0\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown ### 踵位置補正\n",
        "#@markdown 踵のY軸補正値を数値(小数可)で入力して下さい。\n",
        "#@markdown マイナス値を入力すると地面に近付き、プラス値を入力すると地面から遠ざかります。\n",
        "#@markdown ある程度は自動で補正しますが、補正しきれない場合に、設定して下さい。\n",
        "heel_position = 0.0  #@param {type: \"number\"}\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown ### センターZ移動倍率\n",
        "#@markdown センターZ移動に掛ける倍率を数値(小数可)で入力して下さい。\n",
        "#@markdown 値が小さいほど、センターZ移動の幅が小さくなります。\n",
        "#@markdown 0を入力した場合、センターZ軸移動を行いません。\n",
        "center_z_scale = 5.0  #@param {type: \"number\"}\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown ### 滑らかさ\n",
        "#@markdown モーションの円滑化の度数を指定します\n",
        "#@markdown 1以上の整数のみを入力して下さい。\n",
        "#@markdown 度数が大きいほど、円滑化されます。（代わりに動作が小さくなります）\n",
        "smooth_times = 1  #@param {type: \"number\"}\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown ### 移動間引き量\n",
        "#@markdown 移動キー（IK・センター）の間引きに使用する移動量を数値(小数可)で指定します\n",
        "#@markdown 指定された範囲内の移動があった場合に間引きされます。\n",
        "#@markdown 移動間引き量を0にした場合、間引きを行いません。\n",
        "threshold_pos = 0.5  #@param {type: \"number\"}\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown ### 回転間引き角度\n",
        "#@markdown 回転キーの間引きに使用する角度(0～180度まで小数可)を指定します\n",
        "#@markdown 指定された角度以内の回転があった場合に間引きされます。\n",
        "threshold_rot = 3  #@param {type: \"number\"}\n",
        "\n",
        "\n",
        "\n",
        "!echo 解析を開始するフレーム: \"$frame_first\"\n",
        "!echo 映像に映っている最大人数: \"$number_people_max\"\n",
        "!echo 反転フレームリスト: \"$order_specific\"\n",
        "!echo 順番指定リスト: \"$reverse_frames\"\n",
        "!echo ボーン構造CSVファイル: \"$born_model_csv\"\n",
        "!echo IKで出力するか: \"$ik_flag\"\n",
        "!echo 踵位置補正: \"$heel_position\"\n",
        "!echo センターZ移動倍率: \"$center_z_scale\"\n",
        "!echo 滑らかさ: \"$smooth_times\"\n",
        "!echo 移動間引き量: \"$threshold_pos\"\n",
        "!echo 回転間引き角度: \"$threshold_rot\"\n",
        "\n",
        "!echo \"\"\n",
        "!echo 上記で問題ない場合、次に進んで下さい。"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SFWBO6c0YLa4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 自動トレース実行"
      ]
    },
    {
      "metadata": {
        "id": "v1xJDUorYNMi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "フォームの入力がすべて完了したら、下のセルを実行してください。"
      ]
    },
    {
      "metadata": {
        "id": "Zz0bFW4CYQJ9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import time\n",
        "from google.colab import drive\n",
        "import datetime\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "# 処理日時\n",
        "now_str = \"{0:%Y%m%d_%H%M%S}\".format(datetime.datetime.now())\n",
        "\n",
        "# Googleドライブマウント\n",
        "drive.mount('/gdrive')\n",
        "\n",
        "# 起点ディレクトリ\n",
        "base_path = \"/gdrive/My Drive/autotrace\"\n",
        "\n",
        "# 出力フォルダ削除\n",
        "!rm -r ./output\n",
        "\n",
        "output_json = \"/content/output/json/\"\n",
        "output_openpose_avi = \"/content/output/openpose.avi\"\n",
        "\n",
        "! mkdir -p \"$output_json\"\n",
        "\n",
        "# 出力用Googleドライブフォルダ\n",
        "output_path = base_path + \"/\" + now_str\n",
        "! mkdir -p \"$output_path\"\n",
        "\n",
        "! echo ------------------------------------------\n",
        "! echo Openpose\n",
        "! echo ------------------------------------------\n",
        "\n",
        "# Openpose実行\n",
        "! cd openpose/ && ./build/examples/openpose/openpose.bin --video \"$input_video\" --display 0 --model_pose COCO --write_json \"$output_json\" --write_video \"$output_openpose_avi\" --number_people_max \"$number_people_max\" --frame_first \"$frame_first\"\n",
        "\n",
        "# Openpose解析結果のコピー\n",
        "! cp \"$output_openpose_avi\" \"$output_path\"\n",
        "\n",
        "! echo ------------------------------------------\n",
        "! echo FCRN-DepthPrediction-vmd\n",
        "! echo ------------------------------------------\n",
        "\n",
        "! cd FCRN-DepthPrediction-vmd && python tensorflow/predict_video.py --model_path tensorflow/data/NYU_FCRN.ckpt --video_path \"$input_video\" --json_path \"$output_json\" --interval 10 --reverse_frames \"$reverse_frames\" --order_specific \"$order_specific\" --verbose 1 --now \"$now_str\"\n",
        "\n",
        "# 深度結果コピー\n",
        "depth_dir =  output_json + \"_\" + now_str + \"_depth\"\n",
        "! cp -r \"$depth_dir\" \"$output_path\"\n",
        "\n",
        "for i in range(1, number_people_max+1):\n",
        "    ! echo ------------------------------------------\n",
        "    ! echo 3d-pose-baseline-vmd [\"$i\"]\n",
        "    ! echo ------------------------------------------\n",
        "    \n",
        "    target_dir = output_json + \"_\" + now_str + \"_idx0\" + str(i)\n",
        "\n",
        "    !cd ./3d-pose-baseline-vmd && python src/openpose_3dpose_sandbox_vmd.py --camera_frame --residual --batch_norm --dropout 0.5 --max_norm --evaluateActionWise --use_sh --epochs 200 --load 4874200 --gif_fps 30 --verbose 1 --openpose \"$target_dir\" --person_idx 1    \n",
        "    \n",
        "    ! echo ------------------------------------------\n",
        "    ! echo VMD-3d-pose-baseline-multi [\"$i\"]\n",
        "    ! echo ------------------------------------------\n",
        "    \n",
        "    ! cd ./VMD-3d-pose-baseline-multi && python applications/pos2vmd_multi.py -v 2 -t \"$target_dir\" -b \"$born_model_csv\" -c 30 -z \"$center_z_scale\" -s \"$smooth_times\" -p \"$threshold_pos\" -r \"$threshold_rot\" -k \"$is_ik\" -e \"$heel_position\"\n",
        "    \n",
        "    # INDEX別結果コピー\n",
        "    ! cp -r \"$target_dir\" \"$output_path\"\n",
        "\n",
        "    \n",
        "elapsed_time = (time.time() - start_time) / 60\n",
        "    \n",
        "! echo \"■■■■■■■■■■■■■■■■■■■■■■■■\"\n",
        "! echo \"■■すべての処理が終了しました\"\n",
        "! echo \"■■\"\n",
        "! echo \"■■処理にかかった時間：\" \"$elapsed_time\" \"分\"\n",
        "! echo \"■■■■■■■■■■■■■■■■■■■■■■■■\"\n",
        "\n",
        "! echo \"MMD自動トレース実行結果\"\n",
        "\n",
        "! ls -l \"$output_path\""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}